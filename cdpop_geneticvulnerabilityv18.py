# ------------------------------------------------------------------------------------------------
# v18 -- Dec 15, 2013: 
#   0. Added loci select option
# v17 -- Nov 27, 2013:
#	0. Added het to output file. 
# v16 -- Sept 04, 2013:
#	0. Found error in output adding nan.
# v15 -- July 23, 2013 Updates:
#   0. Changes code to reflect varying carrying capacity per subpopulation.
#	1. Change code to refelct fluctuating population sizes in each generation, update metrics.
# v14 -- Feb 22, 2013 Updates:
#	0. Add fake pop holders for indices 0 and 3 as well as 0 and 1 for metrics
#	1. Normalize M by N in population.
#	2. deltaN from intial time not previous time.
# v13 -- Dec 22, 2012 Fixation indices validated with diveRsity program - remove this section of
#	code.
#	Remove multiplicative code, cleanup...
#   Added Hedricks Gh and Ghfun.
# v12 -- Dec 20, 2012 Calculated fixation indices (Gst and D) with program diveRsity. Read in
#	from fixation indices files.
#	Correct Hs and Ht pairwise calculations to match Nei's 1973 gene diversity work.
# v11 -- Dec 7, 2012 Add bias and unbiased estimators.
#		Changed delta Fst abs(Fst_t-Fst_t0).
# v10 -- Dec 3, 2012 Added Jost D code (hopped 9 inbetween work)
# v8 -- Nov 19, 2012 Checking over calcs...
#		Removed if 0 pop, Fst should be 1 -> Fst should be NA, then 
#			recalculate mean, be careful of nans
#		Missmatch in alleles grabbing from output file - calculate from 
#			grid file.
#		Also calculate population here too.
# v7 -- Drop subpopulations from Fst calculation if 0 abundance.
# v6 -- Added rate of change in case time frame is greater than 1 year. 
#		Also, alleles could be 0 and therefor a negative 1 shows up. FIx all negatives to 0.
#		And if 0 population, Fst should be 1?
# v5 -- Add average pairwise Fst here. Remove Dst.
# v4 -- Corrected Nm rescale to carrying capacity. This version does not use Petit. Just
#	counts up alleles. Jost Dst read in from file. and same demographics.
# v3 -- Read in PetitAllelicRichness index, added Jost's Dst. Note need to run 
#	PetitAllelicRichnessv0.py script first.
# v2 -- Added multiple generations
# v1 -- Added monte carlo mean, CIs
# v0 -- Initial script -> psuedo code
# cdfish_geneticvulnerability.py
# Author: Erin L Landguth
# Created: May 22 2011
# Updated: May 22 2011
# Description: 
# Program Input: 
# Program Output: 
# Program Steps:
#	0. User input
# ------------------------------------------------------------------------------------------------
# Import statements
try:
	import numpy as np 
	from numpy.random import *
except ImportError:
	raise ImportError, "Numpy required."
from pylab import *					
import pdb,os,copy		
from random import *	
#-----------------
# User Input
#-----------------
# Directory location of output.csv (folder that contains all the batchruns
dir = "D:/projects/CDFISH/Seattle/Runs/Sull406/IBB_Rickers_100Stray_1396705547/"
 
# Output to name 
outname = "_TEST_"

# XY locations of patches - not used for anything but output.
xyfilename = "D:/projects/CDFISH/Seattle/XY/ReachPts_Nolaketempremoved.csv"

# Number of monte carlo runs
mcruns = 5

# Generation to extract A from
gen = np.arange(0,50,1)

# Number of total individuals
N = 6084

# Number of subpops
n = 406

# Carrying capacity for each subpop - read from file eventually if too big...
#K = 50*np.ones(n)
K = [28,5,15,19,10,14,14,18,40,26,15,33,27,27,13,10,13,10,14,19,12,22,27,18,21,20,13,11,18,26,24,19,13,17,14,20,19,22,17,19,13,17,17,18,43,15,24,20,34,41,24,44,97,31,28,59,24,37,23,26,47,31,54,56,49,35,23,39,22,40,23,45,22,25,40,55,51,54,56,25,67,41,46,37,58,23,29,26,46,39,42,14,26,20,44,24,19,15,29,39,16,36,54,40,22,32,35,50,25,20,14,27,35,19,22,41,23,24,33,28,16,23,37,24,24,37,26,47,28,26,31,26,22,26,23,76,35,28,15,28,14,22,24,63,27,11,9,12,11,12,4,14,10,10,10,10,9,5,5,5,5,5,5,5,4,5,5,5,7,6,6,5,5,3,13,12,7,9,11,11,11,11,11,11,7,5,9,8,5,8,7,7,5,7,13,18,18,19,21,10,10,10,10,10,10,7,10,10,10,10,10,3,7,10,10,10,10,6,10,10,10,10,10,6,6,13,12,8,8,8,7,8,6,5,5,5,5,4,3,3,3,4,4,5,4,4,4,3,3,3,1,2,4,3,4,4,4,5,10,10,9,10,10,10,6,9,10,10,10,10,9,4,5,5,5,9,5,9,7,5,5,5,5,5,5,8,8,6,6,7,7,7,7,7,8,7,8,5,7,9,9,7,5,5,5,5,5,7,7,7,5,7,9,9,9,6,7,9,10,9,7,5,5,5,8,6,5,9,8,5,8,5,5,5,5,5,6,5,9,12,10,8,9,6,7,10,7,9,6,7,12,13,12,10,7,5,7,7,7,6,6,7,7,6,5,5,6,7,4,5,3,3,13,13,13,13,13,13,12,1,10,10,3,10,10,4,4,4,3,2,4,3,3,3,3,4,3,3,3,3,3,2,5,5,5,5]


# Number of alleles - for normalizing the allele diversity
loci = 2
alleles = 3

# Sample the loci to run analysis on (for loci under selection)
selloci = xrange(1,20)
#selloci = xrange(0,1)
selloci = xrange(loci)

# Calculate each statistic - Error (use qnorm(0.975)=1.959964 - couldn't find equivalent qnorm) 
qnorm = 1.959964

# ------------------
# End User Input
# ------------------

# List folders in this dir
def listdirs(folder):
    return [d for d in (os.path.join(folder, d1) for d1 in os.listdir(folder)) if os.path.isdir(d)]
folderList = listdirs(dir)

# Number of initial alleles
maxA = len(selloci)*alleles
alleles = alleles*np.ones(loci,int)

#-----------------------------------------------
# Initial File IO - read in cost distance values
#-----------------------------------------------	
# Open file to extract XY values
xyinputfile = open(xyfilename,'r')

# Read lines from the file
lines = xyinputfile.readlines()

#Close the file
xyinputfile.close()

# Create an empty matrix to append to
xyvalues = []

# Split up each line in file and append to empty matrix for generation specified
for i in xrange(len(lines)):
	thisline = lines[i].split(',')
	xyvalues.append(thisline)

# Get x and y values
X = []
Y = []
cd = []
for i in xrange(len(xyvalues)-1):
	X.append(float(xyvalues[i+1][21]))
	Y.append(float(xyvalues[i+1][22]))
	cd.append(float(xyvalues[i+1][2]))
	
# Delete lines
del(lines)

# --------------------
# Begin gen loop
# --------------------
for igen in xrange(len(gen)):
	
	# ----------------------------	
	#  Preliminary vector storage
	# ----------------------------
	# All information
	He = []
	population = []
	Population = []
	A = []
	Alleles = []
	strayer = []
	Nm = []
	abundance = []
	HS = []
	F = []
	HT = []
	D = []
	Fun = []
	Dun = []
	G = []
	Gun = []

	# Mean storage variable
	He_mean = []	
	population_mean = []
	Population_mean = []
	A_mean = []
	strayer_mean = []
	Nm_mean = []
	deltaF_mean = []
	deltaD_mean = []
	deltaFun_mean = []
	deltaDun_mean = []
	deltaGun_mean = []
	abundance_mean = []
	deltaAbund_mean = []
	F_mean = []
	D_mean = []
	Fun_mean = []
	Dun_mean = []
	G_mean = []
	Gun_mean = []

	# SD storage variable
	He_sd = []
	population_sd = []
	A_sd = []
	strayer_sd = []
	Nm_sd = []
	abundance_sd = []
	F_sd = []
	D_sd = []
	Fun_sd = []
	Dun_sd = []
	G_sd = []
	Gun_sd =[]

	# Left CI storage variable
	He_left = []
	population_left = []
	A_left = []
	strayer_left = []
	Nm_left = []
	deltaF_left = []
	deltaD_left = []
	deltaFun_left = []
	deltaDun_left = []
	deltaGun_left = []
	abundance_left = []
	deltaAbund_left = []
	F_left = []
	D_left = []
	Fun_left = []
	Dun_left = []
	G_left = []
	Gun_left = []
	
	# Right CI storage variable
	He_right = []
	population_right = []
	A_right = []
	strayer_right = []
	Nm_right = []
	deltaF_right = []
	deltaD_right = []
	deltaFun_right = []
	deltaDun_right = []
	deltaGun_right = []
	abundance_right = []
	deltaAbund_right = []
	F_right = []
	D_right = []
	Fun_right = []
	Dun_right = []
	G_right = []
	Gun_right = []
	
	# -----------------------------------	
	# 3. Read in and store metrics
	# -----------------------------------
	# Loop over folders
	for imc in xrange(len(folderList)): 

		# Add a batch spot to the vectors
		strayer.append([])
		Nm.append([])
		abundance.append([])
		F.append([])
		D.append([])
		Fun.append([])
		Dun.append([])
		G.append([])
		Gun.append([])
					
		# ------------------------------------
		# Read in output file for immigrants
		# ------------------------------------
		# Open file to extract number of migrants
		xyinputfile = open(folderList[imc]+"/output.csv",'r')

		# Read lines from the file
		lines = xyinputfile.readlines()

		#Close the file
		xyinputfile.close()

		# Create an empty matrix to append to
		ind = []

		# Split up each line in file and append to empty matrix for generation specified
		for i in xrange(len(lines)):
			thisline = lines[i].split(',')
			ind.append(thisline)

		# Get x and y values	
		if str(ind[gen[igen]+1][33]).find('|') != -1:
			tempList = str(ind[gen[igen]+1][33]).split('|')
		strayer[imc].append(tempList)
			
		# Delete lines
		del(lines)
		
		
		# --------------------------------------------
		# Read in genotypes to get pairwise FST values
		# --------------------------------------------
		# Open file grid* for reading
		inputfile = open(folderList[imc]+"/grid"+str(gen[igen])+".csv",'r')
		
		# Read lines from the file
		lines = inputfile.readlines()

		#Close the file
		inputfile.close()

		# Create an empty matrix to append to
		x = []
		
		# Split up each line in file and append to empty matrix, x
		for l in lines:
			thisline = l.strip('\n').split(',')
			x.append(thisline)
				
		# Create pairwise list and other gene variables
		all_freq_sub = []
		subgridtotal = []
		all_freq_sq_sub = []
		all_freq_pairs = []
		all_freq_sq_pairs = []
		het_sub = []
		het_pairs = []
		Ji = []
		Jij = []
		Dij = []
		for i in xrange(n):
			all_freq_sub.append([])
			subgridtotal.append([])	
			all_freq_sq_sub.append([])
			het_sub.append([])
			het_pairs.append([])
			all_freq_pairs.append([])
			all_freq_sq_pairs.append([])
			Ji.append([])
			Jij.append([])
			Dij.append([])
				
		# Store genetic information: genes[subpop][individual][loci][alleles]
		genes = []
		storeindex = 0
		for i in xrange(n):
			genes.append([])
			for jind in xrange(K[i]):
				genes[i].append([])
				# Check for NA values
				if x[1+jind+(storeindex)][4] != 'NA':
				#if x[1+jind+(i*K[i])][4] != 'NA':
					subgridtotal[i].append(1)
				for k in selloci:
					# Check for NA values
					if x[1+jind+(storeindex)][4] != 'NA':
						temp = x[1+jind+(storeindex)][7+(k*alleles[k]):7+(k*alleles[k])+alleles[k]]
						genes[i][jind].append(temp)
					else:
						genes[i][jind].append(np.nan*np.ones((alleles[k])))
			storeindex = storeindex + K[i]
			subgridtotal[i] = sum(subgridtotal[i])
		
		#---------------------
		# Get population here
		population.append(insert(subgridtotal,0,sum(subgridtotal)))
				
		# Cast genes as an numpy array as byte type
		#genes_array_woNA = np.asarray(genes,dtype='float')
		genes_array = np.asarray(genes)
		
		# Get allele location as seqence from alleles array
		allele_numbers = []
		for i in selloci:
			for j in xrange(alleles[i]):
				allele_numbers.append(j)
		allele_numbers = np.asarray(allele_numbers)
		# The total number of alleles
		total_alleles = len(allele_numbers)
		
		# Get allele frequency for subpopulations and homozygosity
		for i in xrange(n):
			#all_freq_sub[i].append(np.asarray(np.sum(np.asarray(genes_array_wNA[subgrids[i],:,:],dtype='float'),axis=0),dtype = 'float').reshape(total_alleles))
			#np.asarray(genes_array[i,:,:],dtype='float')
			#all_freq_sub[i].append(np.nansum(genes_array[i,:,:],axis=0).reshape(total_alleles))
			all_freq_sub[i].append(np.nansum(np.asarray(genes_array[i][:][:],dtype='float'),axis=0).reshape(total_alleles))
			all_freq_sub[i] = all_freq_sub[i][0]/(2*subgridtotal[i])
			all_freq_sq_sub[i].append(all_freq_sub[i]**2) 
			Ji[i].append(sum(all_freq_sq_sub[i][0])/len(selloci)) # This is Nei's gene identity of ith subpopulation (homog) averaged per locus
			het_sub[i].append(1. - Ji[i][0])	# Will be nan if no individuals in that sub		
			# Next loop through pairwise subpopulations
			for ipair in xrange(n):
				all_freq_pairs[i].append([])
				all_freq_sq_pairs[i].append([])
				het_pairs[i].append([])
				Jij[i].append([])
				# If there are individuals in both subpops
				if subgridtotal[i] != 0 and subgridtotal[ipair] != 0:	
					# Get genes for each populations - convert to frequency of allele in ith subpop
					i_allsum = np.nan_to_num(np.nansum(np.asarray(genes_array[i][:][:],dtype='float'),axis=0))/(2*subgridtotal[i])
					ipair_allsum = np.nan_to_num(np.nansum(np.asarray(genes_array[ipair][:][:],dtype='float'),axis=0))/(2*subgridtotal[ipair])
					Jij[i][ipair].append(sum(i_allsum*ipair_allsum)/len(selloci)) # This is Nei's gene identity b/w ith and jth subpopulation
					all_freq_pairs[i][ipair].append((i_allsum+ipair_allsum).reshape(total_alleles)) # Not correct, but not used...
					all_freq_pairs[i][ipair] = all_freq_pairs[i][ipair][0]/(2*(subgridtotal[i]+subgridtotal[ipair])) # Not correct, but not used...
					all_freq_sq_pairs[i][ipair].append(all_freq_pairs[i][ipair]**2)					
					het_pairs[i][ipair].append(1. - Jij[i][ipair][0])
				# If there are no individuals in both pairs, then make nan
				else:
					all_freq_pairs[i][ipair].append(np.nan)
					all_freq_sq_pairs[i][ipair].append(np.nan)
					het_pairs[i][ipair].append(np.nan)
					Jij[i][ipair].append(np.nan)
		
		# This is Nei's gene diversity b/w ith and jth subpopultion
		for i in xrange(n):
			for ipair in xrange(n):
				Dij[i].append([])
				Dij[i][ipair].append(((Ji[i][0]+Ji[ipair][0])/2)-Jij[i][ipair][0]) 
				
		# ---------------------------
		# Get allelic diversity here
		alleles_sub = []
		# Get the total number of alleles in each subpop - allelic diversity
		for i in xrange(n):
			alleles_sub.append((np.array(all_freq_sub[i]>0.).sum()-1)/float(maxA-1))
		A.append(alleles_sub)
		# Add het numbers
		He.append(transpose(het_sub)[0])
		
		# Replace het nan values with 0.0
		het_pairs = np.nan_to_num(het_pairs)
		het_sub = np.nan_to_num(het_sub)
		Dij = np.nan_to_num(Dij)
		
		#-----------------------
		# Extract metrics
		#-----------------------		
		# Iterate over subpopulations
		storeindex = 0
		for i in xrange(n):	
		
			# ------------------------
			# Calculate abundance here
			# ------------------------
			abundance[imc].append(float(population[imc][i+1])/K[i])
			
			# ------------------------------------
			# Calculate Fst/D here: pairwise Fst/D
			# ------------------------------------
			# Only run Fst if abundance is not 0
			if abundance[imc][i] != 0.0:
				Ftemp = []
				Dtemp = []
				Gtemp = []
				Funtemp = []
				Duntemp = []
				Guntemp = []
				for ipair in xrange(n):					
					# Don't calculate Ftemp for same i and ipair or if abundance is 0
					if i != ipair and population[imc][ipair+1] != 0:						
						
						# Hs and Ht
						HST = 1. - ((Ji[i][0] + Ji[ipair][0])/2)
						HTT = 1. - (((Ji[i][0] + Ji[ipair][0])/2) - ((Dij[i][i][0]+Dij[i][ipair][0]+Dij[ipair][i][0]+Dij[ipair][ipair][0])/2**2))
						
						# Ntilde harmonic mean
						temp1 = 1./population[imc][i+1]
						temp2 = 1./population[imc][ipair+1]
						Ntilde = 2/(temp1+temp2)
						
						# Hs and Ht hat estimators
						HeSestT = ((2*Ntilde)/(2*Ntilde-1))*HST
						HeTestT = (HTT+((HeSestT)/(2*Ntilde*2)))					
						
						Funtemp.append((HeTestT-HeSestT)/HeTestT)					
						Duntemp.append((((HeTestT - HeSestT) / (1-HeSestT)) * (2 / (2-1))))
						Guntemp.append((((HeTestT-HeSestT)/HeTestT)*(2-1+HeSestT)) / ((2-1)*(1-HeSestT)))
						Ftemp.append((HTT-HST)/HTT)					
						Dtemp.append((((HTT - HST) / (1-HST)) * (2 / (2-1))))
					
				# Get average Fst pairwise here (n-1 average pairs)
				Fun[imc].append(sum(Funtemp)/(len(Funtemp)))
				F[imc].append(sum(Ftemp)/(len(Ftemp)))						
				# Get average D pairwise here (n-1 average pairs)
				Dun[imc].append(sum(Duntemp)/len(Duntemp))
				D[imc].append(sum(Dtemp)/len(Dtemp))
				Gun[imc].append(sum(Guntemp)/len(Guntemp))
				
			# If abundance is 0 for that subpopulation, make F == nan
			if abundance[imc][i] == 0.0:
				F[imc].append(np.nan)
				D[imc].append(np.nan)
				Fun[imc].append(np.nan)
				Dun[imc].append(np.nan)
				Gun[imc].append(np.nan)
				# Make A nan also
				A[imc][i] = np.nan
				He[imc][i] = np.nan
							
			#--------------------------
			# Get number of immigrants
			#--------------------------
			Nm[imc].append([])
					
			# If abundance is 0 for that subpopulation, make nan
			if abundance[imc][i] == 0.0:
				Nm[imc][i].append(np.nan)
			else:
				# Here normalize by abundance in that population (used to be K).
				Nm[imc][i].append(float(strayer[imc][0][i]) / (abundance[imc][i] * K[i]))
			storeindex = storeindex + K[i]
	# Turn into numpy arrays
	Nm = np.asarray(Nm)
	abundance = np.asarray(abundance)
	# Now make 0 abundance nan
	abundance[np.where(abundance == 0.0)] = np.nan
	F = np.asarray(F)
	D = np.asarray(D)
	Fun = np.asarray(Fun)
	Dun = np.asarray(Dun)
	Gun = np.asarray(Gun)
	A = np.asarray(A)
	# Negative A values (means 0 population), turn to nan CAREFULLL!!!!! is this always the case
	A[np.where(A <= 0.)] = np.nan
	He = np.asarray(He)
	He[np.where(He <= 0.)] = np.nan
		
	# ----------------------------------------------------------------------------------	
	# Calculate mean, sd, and confidence intervals for each subpopulation across each MC 
	# ----------------------------------------------------------------------------------	
	# Looptime Loop begin
	for imc in xrange(n):
		
		# Calculate each statistic - Mean
		Nm_mean.append(ma.average(ma.masked_invalid(Nm[:,imc])))
		abundance_mean.append(ma.average(ma.masked_invalid(abundance[:,imc])))
		F_mean.append(ma.average(ma.masked_invalid(F[:,imc])))
		D_mean.append(ma.average(ma.masked_invalid(D[:,imc])))
		Fun_mean.append(ma.average(ma.masked_invalid(Fun[:,imc])))
		Dun_mean.append(ma.average(ma.masked_invalid(Dun[:,imc])))
		Gun_mean.append(ma.average(ma.masked_invalid(Gun[:,imc])))
		A_mean.append(ma.average(ma.masked_invalid(A[:,imc])))
		He_mean.append(ma.average(ma.masked_invalid(He[:,imc])))
		
		# SD storage variable
		Nm_sd.append(ma.std(ma.masked_invalid(Nm[:,imc]))) 
		abundance_sd.append(ma.std(ma.masked_invalid(abundance[:,imc])))
		F_sd.append(ma.std(ma.masked_invalid(F[:,imc])))
		D_sd.append(ma.std(ma.masked_invalid(D[:,imc])))
		Fun_sd.append(ma.std(ma.masked_invalid(Fun[:,imc])))
		Dun_sd.append(ma.std(ma.masked_invalid(Dun[:,imc])))
		Gun_sd.append(ma.std(ma.masked_invalid(Gun[:,imc])))
		A_sd.append(ma.std(ma.masked_invalid(A[:,imc])))
		He_sd.append(ma.std(ma.masked_invalid(He[:,imc])))

		# Calculate each statistic - Error (use qnorm(0.975)=1.959964 - couldn't find equivalent qnorn) 
		Nm_error = qnorm*Nm_sd[imc]/np.sqrt(mcruns)
		abundance_error = qnorm*abundance_sd[imc]/np.sqrt(mcruns)
		F_error = qnorm*F_sd[imc]/np.sqrt(mcruns)
		D_error = qnorm*D_sd[imc]/np.sqrt(mcruns)
		Fun_error = qnorm*Fun_sd[imc]/np.sqrt(mcruns)
		Dun_error = qnorm*Dun_sd[imc]/np.sqrt(mcruns)
		Gun_error = qnorm*Gun_sd[imc]/np.sqrt(mcruns)
		A_error = qnorm*A_sd[imc]/np.sqrt(mcruns)
		He_error = qnorm*He_sd[imc]/np.sqrt(mcruns)

		# Left CI storage variable
		Nm_left.append(Nm_mean[imc]-Nm_error)
		abundance_left.append(abundance_mean[imc]-abundance_error)
		F_left.append(F_mean[imc]-F_error)
		D_left.append(D_mean[imc]-D_error)
		Fun_left.append(Fun_mean[imc]-Fun_error)
		Dun_left.append(Dun_mean[imc]-Dun_error)
		Gun_left.append(Gun_mean[imc]-Gun_error)
		A_left.append(A_mean[imc]-A_error)
		He_left.append(He_mean[imc]-He_error)
		
		# Right CI storage variable
		Nm_right.append(Nm_mean[imc]+Nm_error)
		abundance_right.append(abundance_mean[imc]+abundance_error)
		F_right.append(F_mean[imc]+F_error)
		D_right.append(D_mean[imc]+D_error)
		Fun_right.append(Fun_mean[imc]+Fun_error)
		Dun_right.append(Dun_mean[imc]+Dun_error)
		Gun_right.append(Gun_mean[imc]+Gun_error)
		A_right.append(A_mean[imc]+A_error)
		He_right.append(He_mean[imc]+He_error)
		
		# -----------------------------------------------
		# Calculate change in abundance and change in Fst
		# -----------------------------------------------
		# For deltaF and deltaAbund
		if igen == 0:
			deltaF_mean.append(0.0)
			deltaF_right.append(0.0)
			deltaF_left.append(0.0)
			deltaD_mean.append(0.0)
			deltaD_right.append(0.0)
			deltaD_left.append(0.0)
			deltaFun_mean.append(0.0)
			deltaFun_right.append(0.0)
			deltaFun_left.append(0.0)
			deltaDun_mean.append(0.0)
			deltaDun_right.append(0.0)
			deltaDun_left.append(0.0)
			deltaGun_mean.append(0.0)
			deltaGun_right.append(0.0)
			deltaGun_left.append(0.0)
			deltaAbund_mean.append(0.0)
			deltaAbund_right.append(0.0)
			deltaAbund_left.append(0.0)
			
		else:
			deltaF_mean.append(abs(F_mean[imc]-F0_mean[imc]))
			deltaF_right.append(abs(F_right[imc]-F0_right[imc]))
			deltaF_left.append(abs(F_left[imc]-F0_left[imc]))
			deltaD_mean.append(abs(D_mean[imc]-D0_mean[imc]))
			deltaD_right.append(abs(D_right[imc]-D0_right[imc]))
			deltaD_left.append(abs(D_left[imc]-D0_left[imc]))
			deltaFun_mean.append(abs(Fun_mean[imc]-Fun0_mean[imc]))
			deltaFun_right.append(abs(Fun_right[imc]-Fun0_right[imc]))
			deltaFun_left.append(abs(Fun_left[imc]-Fun0_left[imc]))
			deltaDun_mean.append(abs(Dun_mean[imc]-Dun0_mean[imc]))
			deltaDun_right.append(abs(Dun_right[imc]-Dun0_right[imc]))
			deltaDun_left.append(abs(Dun_left[imc]-Dun0_left[imc]))
			deltaGun_mean.append(abs(Gun_mean[imc]-Gun0_mean[imc]))
			deltaGun_right.append(abs(Gun_right[imc]-Gun0_right[imc]))
			deltaGun_left.append(abs(Gun_left[imc]-Gun0_left[imc]))
			
			deltaAbund_mean.append((abundance_mean[imc]-abund0_mean[imc]))
			deltaAbund_right.append((abundance_right[imc]-abund0_right[imc]))
			deltaAbund_left.append((abundance_left[imc]-abund0_left[imc]))
			# Condition where population was extinct (nan) in previous generation - check
			if abundance_mean[imc] == np.nan:
				pdb.set_trace()
			# Piecewise scale here - if abundance goes up that is good! Make 0
			if deltaAbund_mean[imc] > 0.0:
				deltaAbund_mean[imc] = 0.0
				deltaAbund_right[imc] = 0.0
				deltaAbund_left[imc] = 0.0		
						
	#---------------
	# Weight values
	#---------------
	weightGvalues_meanF = []
	weightGvalues_leftF = []
	weightGvalues_rightF = []
	weightDvalues_mean = []
	weightDvalues_left = []
	weightDvalues_right = []
	weightGvalues_meanD = []
	weightGvalues_leftD = []
	weightGvalues_rightD = []
	weightGvalues_meanFun = []
	weightGvalues_leftFun = []
	weightGvalues_rightFun = []
	weightGvalues_meanDun = []
	weightGvalues_leftDun = []
	weightGvalues_rightDun = []
	weightGvalues_meanGun = []
	weightGvalues_leftGun = []
	weightGvalues_rightGun = []
	subpop = []
	combinedF = []
	averagedF = []
	averagedD = []	
	averagedFun = []
	averagedDun = []
	averagedGun = []
			
	for i in xrange(n):		
		# Additive with F
		val = (-A_mean[i]+1) + F_mean[i] + (deltaF_mean[i]) 
		weightGvalues_meanF.append(val)
		val = (-A_left[i]+1) + F_left[i] + (deltaF_left[i]) 
		weightGvalues_leftF.append(val)
		val = (-A_right[i]+1) + F_right[i] + (deltaF_right[i]) 
		weightGvalues_rightF.append(val)
		val = (-abundance_mean[i]+1) + (-Nm_mean[i]+1) + (-deltaAbund_mean[i])
		weightDvalues_mean.append(val)
		val = (-abundance_left[i]+1) + (-Nm_left[i]+1) + (-deltaAbund_left[i])
		weightDvalues_left.append(val)
		val = (-abundance_right[i]+1) + (-Nm_right[i]+1) + (-deltaAbund_right[i])
		weightDvalues_right.append(val)
		subpop.append(i+1)
		combinedF.append(weightGvalues_meanF[i]+ weightDvalues_mean[i])
		averagedF.append((weightGvalues_meanF[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with D
		val = (-A_mean[i]+1) + D_mean[i] + (deltaD_mean[i]) 
		weightGvalues_meanD.append(val)
		val = (-A_left[i]+1) + D_left[i] + (deltaD_left[i]) 
		weightGvalues_leftD.append(val)
		val = (-A_right[i]+1) + D_right[i] + (deltaD_right[i]) 
		weightGvalues_rightD.append(val)
		averagedD.append((weightGvalues_meanD[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with F unbiased
		val = (-A_mean[i]+1) + Fun_mean[i] + (deltaFun_mean[i]) 
		weightGvalues_meanFun.append(val)
		val = (-A_left[i]+1) + Fun_left[i] + (deltaFun_left[i]) 
		weightGvalues_leftFun.append(val)
		val = (-A_right[i]+1) + Fun_right[i] + (deltaFun_right[i]) 
		weightGvalues_rightFun.append(val)
		averagedFun.append((weightGvalues_meanFun[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with D unbiased
		val = (-A_mean[i]+1) + Dun_mean[i] + (deltaDun_mean[i]) 
		weightGvalues_meanDun.append(val)
		val = (-A_left[i]+1) + Dun_left[i] + (deltaDun_left[i]) 
		weightGvalues_leftDun.append(val)
		val = (-A_right[i]+1) + Dun_right[i] + (deltaDun_right[i]) 
		weightGvalues_rightDun.append(val)
		averagedDun.append((weightGvalues_meanDun[i]+ weightDvalues_mean[i])/2.)
		
		# Additive with G' unbiased
		val = (-A_mean[i]+1) + Gun_mean[i] + (deltaGun_mean[i]) 
		weightGvalues_meanGun.append(val)
		val = (-A_left[i]+1) + Gun_left[i] + (deltaGun_left[i]) 
		weightGvalues_leftGun.append(val)
		val = (-A_right[i]+1) + Gun_right[i] + (deltaGun_right[i]) 
		weightGvalues_rightGun.append(val)
		averagedGun.append((weightGvalues_meanGun[i]+ weightDvalues_mean[i])/2.)
		
	# ----------------------
	# Output to file
	#-----------------------

	# Create file to write info to
	outputfile = open(dir+'vuln_summary'+outname+str(gen[igen])+'.csv','w')

	# Write out the titles
	# Add Titles from xypoints
	outputtitle = ['Subpopulation','X','Y',\
	'He_Mean','He_Left','He_Right',\
	'ADiv_Mean','ADiv_Left','ADiv_Right',\
	'G_Mean','G_Left','G_Right',\
	'deltaG_Mean','deltaG_Left','deltaG_Right',\
	'D_Mean','D_Left','D_Right',\
	'deltaD_Mean','deltaD_Left','deltaD_Right',\
	'Gest_Mean','Gest_Left','Gest_Right',\
	'deltaGest_Mean','deltaGest_Left','deltaGest_Right',\
	'Dest_Mean','Dest_Left','Dest_Right',\
	'deltaDest_Mean','deltaDest_Left','deltaDest_Right',\
	'Ghedest_Mean','Ghedest_Left','Ghedest_Right',\
	'deltaGhedest_Mean','deltaGhedest_Left','deltaGhedest_Right',\
	'Abundance_Mean','Abundance_Left','Abundance_Right',\
	'Nm_Mean','Nm_Left','Nm_Right',\
	'deltaAbund_Mean','deltaAbund_Left','deltaAbund_Right',\
	'DemoIndex_Mean_add','DemoIndex_Left_add','DemoIndex_Right_add',
	'GeneticIndex_Mean_add_G','GeneticIndex_Left_add_G','GeneticIndex_Right_add_G',\
	'GeneticIndex_Mean_add_D','GeneticIndex_Left_add_D','GeneticIndex_Right_add_D',\
	'GeneticIndex_Mean_add_Gest','GeneticIndex_Left_add_Gest','GeneticIndex_Right_add_Gest',\
	'GeneticIndex_Mean_add_Dest','GeneticIndex_Left_add_Dest','GeneticIndex_Right_add_Dest',\
	'GeneticIndex_Mean_add_Ghedest','GeneticIndex_Left_add_Ghedest','GeneticIndex_Right_add_Ghedest',\
	'Combined_Mean_G','Averaged_Mean_G','Averaged_Mean_D','Averaged_Mean_Gest','Averaged_Mean_Dest','Averaged_Mean_Ghedest']

	# Write out the title
	for i in range(len(outputtitle)-1):
		outputfile.write(outputtitle[i])
		outputfile.write(',')
	# To get return character on the end
	outputfile.write(str(outputtitle[len(outputtitle)-1]))				
	outputfile.write('\n')
	
	# Write to file
	for i in range(n):

		outputfile.write(str(i+1)+',')
		outputfile.write(str(X[i])+',')
		outputfile.write(str(Y[i])+',')
		outputfile.write(str(He_mean[i])+',')
		outputfile.write(str(He_left[i])+',')
		outputfile.write(str(He_right[i])+',')
		outputfile.write(str(A_mean[i])+',')
		outputfile.write(str(A_left[i])+',')
		outputfile.write(str(A_right[i])+',')
		outputfile.write(str(F_mean[i])+',')
		outputfile.write(str(F_left[i])+',')
		outputfile.write(str(F_right[i])+',')
		outputfile.write(str(deltaF_mean[i])+',')
		outputfile.write(str(deltaF_left[i])+',')
		outputfile.write(str(deltaF_right[i])+',')
		outputfile.write(str(D_mean[i])+',')
		outputfile.write(str(D_left[i])+',')
		outputfile.write(str(D_right[i])+',')
		outputfile.write(str(deltaD_mean[i])+',')
		outputfile.write(str(deltaD_left[i])+',')
		outputfile.write(str(deltaD_right[i])+',')
		outputfile.write(str(Fun_mean[i])+',')
		outputfile.write(str(Fun_left[i])+',')
		outputfile.write(str(Fun_right[i])+',')
		outputfile.write(str(deltaFun_mean[i])+',')
		outputfile.write(str(deltaFun_left[i])+',')
		outputfile.write(str(deltaFun_right[i])+',')
		outputfile.write(str(Dun_mean[i])+',')
		outputfile.write(str(Dun_left[i])+',')
		outputfile.write(str(Dun_right[i])+',')
		outputfile.write(str(deltaDun_mean[i])+',')
		outputfile.write(str(deltaDun_left[i])+',')
		outputfile.write(str(deltaDun_right[i])+',')
		outputfile.write(str(Gun_mean[i])+',')
		outputfile.write(str(Gun_left[i])+',')
		outputfile.write(str(Gun_right[i])+',')
		outputfile.write(str(deltaGun_mean[i])+',')
		outputfile.write(str(deltaGun_left[i])+',')
		outputfile.write(str(deltaGun_right[i])+',')
		outputfile.write(str(abundance_mean[i])+',')
		outputfile.write(str(abundance_left[i])+',')
		outputfile.write(str(abundance_right[i])+',')
		outputfile.write(str(Nm_mean[i])+',')
		outputfile.write(str(Nm_left[i])+',')
		outputfile.write(str(Nm_right[i])+',')		
		outputfile.write(str(deltaAbund_mean[i])+',')
		outputfile.write(str(deltaAbund_left[i])+',')
		outputfile.write(str(deltaAbund_right[i])+',')
		outputfile.write(str(weightDvalues_mean[i])+',')
		outputfile.write(str(weightDvalues_left[i])+',')
		outputfile.write(str(weightDvalues_right[i])+',')
		outputfile.write(str(weightGvalues_meanF[i])+',')
		outputfile.write(str(weightGvalues_leftF[i])+',')
		outputfile.write(str(weightGvalues_rightF[i])+',')
		outputfile.write(str(weightGvalues_meanD[i])+',')
		outputfile.write(str(weightGvalues_leftD[i])+',')
		outputfile.write(str(weightGvalues_rightD[i])+',')
		outputfile.write(str(weightGvalues_meanFun[i])+',')
		outputfile.write(str(weightGvalues_leftFun[i])+',')
		outputfile.write(str(weightGvalues_rightFun[i])+',')
		outputfile.write(str(weightGvalues_meanDun[i])+',')
		outputfile.write(str(weightGvalues_leftDun[i])+',')
		outputfile.write(str(weightGvalues_rightDun[i])+',')
		outputfile.write(str(weightGvalues_meanGun[i])+',')
		outputfile.write(str(weightGvalues_leftGun[i])+',')
		outputfile.write(str(weightGvalues_rightGun[i])+',')
		outputfile.write(str(combinedF[i])+',')
		outputfile.write(str(averagedF[i])+',')
		outputfile.write(str(averagedD[i])+',')
		outputfile.write(str(averagedFun[i])+',')
		outputfile.write(str(averagedDun[i])+',')	
		outputfile.write(str(averagedGun[i])+'\n')
	# Write out 0 and 3 for GIS output
	outputfile.write(str(n+1)+',')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')		
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('0,')
	outputfile.write('0,')
	outputfile.write('0,')
	outputfile.write('0,')
	outputfile.write('0,')	
	outputfile.write('0\n')
	outputfile.write(str(n+2)+',')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')		
	outputfile.write('1,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('3,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('3,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('3,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('3,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('3,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('3,')
	outputfile.write(',')
	outputfile.write(',')
	outputfile.write('3,')
	outputfile.write('3,')
	outputfile.write('3,')
	outputfile.write('3,')
	outputfile.write('3,')	
	outputfile.write('3\n')
		
	print '\n'
	print 'The file has been created', dir+'vuln_summary'+str(gen[igen])
				
	# Close file
	outputfile.close()	

	# Store differentiation and abundance values in temp location for previous generation to get change
	if igen == 0:
		
		F0_mean = F_mean
		F0_right = F_right
		F0_left = F_left
		D0_mean = D_mean
		D0_right = D_right
		D0_left = D_left
		Fun0_mean = Fun_mean
		Fun0_right = Fun_right
		Fun0_left = Fun_left
		Dun0_mean = Dun_mean
		Dun0_right = Dun_right
		Dun0_left = Dun_left
		Gun0_mean = Gun_mean
		Gun0_right = Gun_right
		Gun0_left = Gun_left
		# Here replace the NAN with 1s for the delta values....
		F0_mean = np.asarray(F0_mean)
		F0_right = np.asarray(F0_right)
		F0_left = np.asarray(F0_left)
		D0_mean = np.asarray(D0_mean)
		D0_right = np.asarray(D0_right)
		D0_left = np.asarray(D0_left)
		Fun0_mean = np.asarray(Fun0_mean)
		Fun0_right = np.asarray(Fun0_right)
		Fun0_left = np.asarray(Fun0_left)
		Dun0_mean = np.asarray(Dun0_mean)
		Dun0_right = np.asarray(Dun0_right)
		Dun0_left = np.asarray(Dun0_left)
		Gun0_mean = np.asarray(Gun0_mean)
		Gun0_right = np.asarray(Gun0_right)
		Gun0_left = np.asarray(Gun0_left)
		
		F0_mean[isnan(F0_mean)==True] = 1.0
		F0_right[isnan(F0_right)==True] = 1.0
		F0_left[isnan(F0_left) == True] = 1.0
		D0_mean[isnan(D0_mean) == True] = 1.0
		D0_right[isnan(D0_right) == True] = 1.0
		D0_left[isnan(D0_left) == True] = 1.0
		Fun0_mean[isnan(Fun0_mean) == True] = 1.0
		Fun0_right[isnan(Fun0_right) == True] = 1.0
		Fun0_left[isnan(Fun0_left) == True] = 1.0
		Dun0_mean[isnan(Dun0_mean) == True] = 1.0
		Dun0_right[isnan(Dun0_right) == True] = 1.0
		Dun0_left[isnan(Dun0_left) == True] = 1.0
		Gun0_mean[isnan(Gun0_mean) == True] = 1.0
		Gun0_right[isnan(Gun0_right) == True] = 1.0
		Gun0_left[isnan(Gun0_left) == True] = 1.0
		
		abund0_mean = abundance_mean
		abund0_right = abundance_right
		abund0_left = abundance_left
		abund0_mean = np.asarray(abund0_mean)
		abund0_right = np.asarray(abund0_right)
		abund0_left = np.asarray(abund0_left)
		# Here replace the NAN with 0s for the dleta values	
		abund0_mean[isnan(abund0_mean)==True] = 0.0
		abund0_right[isnan(abund0_right)==True] = 0.0
		abund0_left[isnan(abund0_left)==True] = 0.0
		